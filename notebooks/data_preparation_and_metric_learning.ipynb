{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1508223,"sourceType":"datasetVersion","datasetId":888440}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pytorch_metric_learning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:52:49.465596Z","iopub.execute_input":"2025-02-01T21:52:49.465912Z","iopub.status.idle":"2025-02-01T21:52:53.912303Z","shell.execute_reply.started":"2025-02-01T21:52:49.465884Z","shell.execute_reply":"2025-02-01T21:52:53.911400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install faiss-gpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:52:53.913674Z","iopub.execute_input":"2025-02-01T21:52:53.913929Z","iopub.status.idle":"2025-02-01T21:52:59.887775Z","shell.execute_reply.started":"2025-02-01T21:52:53.913907Z","shell.execute_reply":"2025-02-01T21:52:59.886820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pytorch_lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:52:59.889885Z","iopub.execute_input":"2025-02-01T21:52:59.890144Z","iopub.status.idle":"2025-02-01T21:53:03.268147Z","shell.execute_reply.started":"2025-02-01T21:52:59.890122Z","shell.execute_reply":"2025-02-01T21:53:03.267068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport random\nimport json\nimport scipy.io\nimport time\nimport glob\nimport shutil\nimport yaml\nimport xml.etree.ElementTree as ET\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset, random_split\nimport torch.nn as nn\nfrom torch.optim import Adadelta, Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.tensorboard import summary, writer, SummaryWriter\nfrom torchvision.datasets import ImageFolder\nimport torchmetrics\nfrom IPython.display import display\nfrom ipywidgets import IntProgress\n\n\nfrom torchvision import transforms\nfrom torchvision.models import resnet18\nimport torch.functional as F\n\nfrom PIL import Image \nfrom tqdm.auto import tqdm\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom pytorch_metric_learning.losses import TripletMarginLoss\nfrom pytorch_metric_learning.miners import BatchEasyHardMiner, TripletMarginMiner\nfrom pytorch_metric_learning import distances, losses, miners, reducers, testers\nfrom pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\nimport pytorch_lightning as pl\nimport faiss\nfrom pytorch_metric_learning.utils.inference import CustomKNN\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.callbacks import LearningRateMonitor\nfrom pytorch_lightning.loggers import TensorBoardLogger, CSVLogger","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:03.269851Z","iopub.execute_input":"2025-02-01T21:53:03.270140Z","iopub.status.idle":"2025-02-01T21:53:14.717175Z","shell.execute_reply.started":"2025-02-01T21:53:03.270117Z","shell.execute_reply":"2025-02-01T21:53:14.716475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"progress_bar = IntProgress(min=0, max=100, description='Обучение модели:')\ndisplay(progress_bar)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:14.717902Z","iopub.execute_input":"2025-02-01T21:53:14.718408Z","iopub.status.idle":"2025-02-01T21:53:14.727637Z","shell.execute_reply.started":"2025-02-01T21:53:14.718384Z","shell.execute_reply":"2025-02-01T21:53:14.726602Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Seed","metadata":{}},{"cell_type":"code","source":"SEED = 42\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:14.728651Z","iopub.execute_input":"2025-02-01T21:53:14.729040Z","iopub.status.idle":"2025-02-01T21:53:14.780677Z","shell.execute_reply.started":"2025-02-01T21:53:14.729004Z","shell.execute_reply":"2025-02-01T21:53:14.779841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Вспомогательная функция для отрисовки изображений","metadata":{}},{"cell_type":"code","source":"def plot_image(image, label):\n\t'''\n\tВспомогательная функция для plotting'а тензора torch\n\t\n\tПараметры:\n\t-image: TorchTensor\n\t-label: str для написания заголовка\n\t'''\n\timg = image.squeeze(0).permute(1, 2, 0).numpy()\n\tfig = plt.figure(figsize = (4, 4))\n\tplt.imshow(img)\n\tplt.title(label)\n\tplt.tight_layout()\n\tplt.axis('off')\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:14.781496Z","iopub.execute_input":"2025-02-01T21:53:14.781776Z","iopub.status.idle":"2025-02-01T21:53:14.786578Z","shell.execute_reply.started":"2025-02-01T21:53:14.781750Z","shell.execute_reply":"2025-02-01T21:53:14.785825Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Дополнительные функции","metadata":{}},{"cell_type":"code","source":"# Базовый transform\nbase_transform = transforms.Compose(\n    [\n        transforms.Resize((300, 300)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]\n)\n\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\n# Денормализация изображения для вывода через plt.imhsow()\ndef unnormalize(tensor, mean=mean, std=std):\n    for t, m, s in zip(tensor, mean, std):\n        t.mul_(s).add_(m)\n    return tensor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:14.787254Z","iopub.execute_input":"2025-02-01T21:53:14.787475Z","iopub.status.idle":"2025-02-01T21:53:14.804583Z","shell.execute_reply.started":"2025-02-01T21:53:14.787457Z","shell.execute_reply":"2025-02-01T21:53:14.803855Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Создание каталогов","metadata":{}},{"cell_type":"code","source":"DIR_PATH = '/kaggle/input/logodet3k/LogoDet-3K'\n\nlogo_dataset = pd.DataFrame(glob.glob(f\"{DIR_PATH}/*/*/*\"), columns=[\"file_path\"])\nlogo_dataset[\"extension\"] = logo_dataset[\"file_path\"].apply(lambda x: x.split(\".\")[-1])\nlogo_dataset[\"logo_category\"] = logo_dataset[\"file_path\"].apply(lambda x: x.split(os.sep)[-3])\nlogo_dataset[\"logo_name\"] = logo_dataset[\"file_path\"].apply(lambda x: x.split(os.sep)[-2])\nlogo_dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:14.806701Z","iopub.execute_input":"2025-02-01T21:53:14.806891Z","iopub.status.idle":"2025-02-01T21:53:39.644183Z","shell.execute_reply.started":"2025-02-01T21:53:14.806874Z","shell.execute_reply":"2025-02-01T21:53:39.643441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def filter_dataset(logo_dataset:pd.DataFrame = logo_dataset, \n                  q:float = 0.05):\n    '''\n    Функция для фильтрации (сокращения) исходного датасета.\n    В этом есть смысл ввиду предположения избыточности полного набора данных \n    при решении задачи Object Detection c одним классом (logo)\n\n    Параметры:\n    -logo_dataset: исходный датасет с логотипами (pd.DataFrame, default: logo_dataset)\n    -q: квантиль для подрезки распределения (убрать небольшое число логотипов) (float, default: 0.05)\n    '''\n\n    logo_dataset = logo_dataset[logo_dataset['logo_category'] != 'Medical']\n    assert logo_dataset['extension'].value_counts()['jpg'] == logo_dataset['extension'].value_counts()['xml']\n    logo_dataset = logo_dataset[logo_dataset['logo_category'] != 'Sports']\n    assert logo_dataset['extension'].value_counts()['jpg'] == logo_dataset['extension'].value_counts()['xml']\n    value_counts = logo_dataset['logo_name'].value_counts()\n    threshold = np.quantile(value_counts.values, q = q)\n    logo_names_to_remove = value_counts[value_counts < threshold].index\n    logo_dataset = logo_dataset[~logo_dataset['logo_name'].isin(logo_names_to_remove)]\n    assert logo_dataset['extension'].value_counts()['jpg'] == logo_dataset['extension'].value_counts()['xml']\n\n    return logo_dataset\n    \nlogo_dataset_copy = logo_dataset.copy()\nlogo_dataset_copy = filter_dataset(logo_dataset = logo_dataset_copy, \n                                  q = 0.25)\nprint(f\"Dataset shape: {logo_dataset_copy.shape}\")\nprint(f\"No. of .jpg files {logo_dataset_copy['extension'].value_counts()['jpg']}\")\nprint(f\"No. of .xml files {logo_dataset_copy['extension'].value_counts()['xml']}\")\nlogo_dataset_copy.head()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:39.645426Z","iopub.execute_input":"2025-02-01T21:53:39.645777Z","iopub.status.idle":"2025-02-01T21:53:40.064210Z","shell.execute_reply.started":"2025-02-01T21:53:39.645741Z","shell.execute_reply":"2025-02-01T21:53:40.063375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logo_dataset_copy[\"logo_name\"].value_counts().reset_index().plot(\n    x=\"logo_name\", y=\"count\", figsize=(10,5), title=\"Distribution of logo img counts\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.065151Z","iopub.execute_input":"2025-02-01T21:53:40.065433Z","iopub.status.idle":"2025-02-01T21:53:40.380497Z","shell.execute_reply.started":"2025-02-01T21:53:40.065408Z","shell.execute_reply":"2025-02-01T21:53:40.379645Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Вспомогательные словари формата ```{'logo_name': label} и {label: 'logo_name'}``` ","metadata":{}},{"cell_type":"code","source":"classname2idx = {logo_name: idx for idx, logo_name in enumerate(sorted(logo_dataset_copy[\"logo_name\"].unique()))}\nidx2classname = {idx: logo_name for logo_name, idx in classname2idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.381341Z","iopub.execute_input":"2025-02-01T21:53:40.381610Z","iopub.status.idle":"2025-02-01T21:53:40.404498Z","shell.execute_reply.started":"2025-02-01T21:53:40.381576Z","shell.execute_reply":"2025-02-01T21:53:40.403602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logo_dataset_copy['is_train'] = True\ntrain_logo_dataset, test_logo_dataset = train_test_split(logo_dataset_copy, test_size=0.25, random_state=SEED)\ntest_logo_dataset['is_train'] = False\nfinal_logo_dataset = pd.concat([train_logo_dataset, test_logo_dataset])\nfinal_logo_dataset.reset_index(drop=True, inplace=True)\nprint(f\"Logo dataset shape: {final_logo_dataset.shape}\")\nfinal_logo_dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.405313Z","iopub.execute_input":"2025-02-01T21:53:40.405546Z","iopub.status.idle":"2025-02-01T21:53:40.571360Z","shell.execute_reply.started":"2025-02-01T21:53:40.405526Z","shell.execute_reply":"2025-02-01T21:53:40.570503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Необходимо закодировать метки для обучения","metadata":{}},{"cell_type":"code","source":"final_logo_dataset['label'] = final_logo_dataset['logo_name'].map(classname2idx)\nprint(f\"Number of classes: {len(final_logo_dataset['label'].unique())}\")\nprint(f\"Final logo dataset shape: {final_logo_dataset.shape[0]}\")\nfinal_logo_dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.572278Z","iopub.execute_input":"2025-02-01T21:53:40.572592Z","iopub.status.idle":"2025-02-01T21:53:40.636495Z","shell.execute_reply.started":"2025-02-01T21:53:40.572561Z","shell.execute_reply":"2025-02-01T21:53:40.635731Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Элементы YOLO preprocessing могут быть полезны для получения общего каталога","metadata":{}},{"cell_type":"code","source":"example_xml_file = '/kaggle/input/logodet3k/LogoDet-3K/Clothes/2xist/1.xml'\n\ndef convert_to_YOLO_format(xml_path:str = example_xml_file, output_dir = None,\n                          name2class_dict:dict = classname2idx):\n    '''\n    Функция по заданному файлу (.xml) создает файл c аннотациями для YOLO\n\n    Параметры:\n    -xml_path: путь к файлу формата .xml (str, default: example_xml_file)\n    -output_dir: путь для записи YOLO аннотаций (default: None)\n    -name2class_dict: словарь для получения классов-меток (dict, default: classname2idx)\n    '''\n    \n    yolo_lines = []\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n    image_width = float(root.find(\"size/width\").text)\n    image_height = float(root.find(\"size/height\").text)\n    depth = float(root.find(\"size/depth\").text)\n\n    for obj in root.findall('object'):\n        class_name = obj.find('name').text\n        bbox = obj.find('bndbox')\n        xmin = float(bbox.find('xmin').text)\n        ymin = float(bbox.find('ymin').text)\n        xmax = float(bbox.find('xmax').text)\n        ymax = float(bbox.find('ymax').text)\n        x_center = (xmin + xmax) / 2 / image_width\n        y_center = (ymin + ymax) / 2 / image_height\n        width = (xmax - xmin) / image_width\n        height = (ymax - ymin) / image_height\n        class_index = classname2idx.get(class_name, 0)\n        yolo_line = f\"{class_index} {x_center} {y_center} {width} {height}\"\n        yolo_lines.append(yolo_line)\n        \n    if output_dir is not None:\n        with open(output_dir, \"w\") as f:\n            f.write(\"\\n\".join(yolo_lines))\n            \n    return yolo_lines\n\nexample = convert_to_YOLO_format(name2class_dict = {})\nprint(example)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.637464Z","iopub.execute_input":"2025-02-01T21:53:40.637796Z","iopub.status.idle":"2025-02-01T21:53:40.649179Z","shell.execute_reply.started":"2025-02-01T21:53:40.637763Z","shell.execute_reply":"2025-02-01T21:53:40.648409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Функция для построения рабочей директории","metadata":{}},{"cell_type":"code","source":"dataset_dst_dir = \"/kaggle/working/logodet3k\"\nif os.path.exists(dataset_dst_dir):\n    shutil.rmtree(dataset_dst_dir)\nos.makedirs(f\"{dataset_dst_dir}/train\", exist_ok=True)\nos.makedirs(f\"{dataset_dst_dir}/val\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.649994Z","iopub.execute_input":"2025-02-01T21:53:40.650291Z","iopub.status.idle":"2025-02-01T21:53:40.662460Z","shell.execute_reply.started":"2025-02-01T21:53:40.650262Z","shell.execute_reply":"2025-02-01T21:53:40.661814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def copy_to_working_dir(sample, \n                    classnam2idx:dict = classname2idx):\n\n    '''\n    Функция для создания каталога обучения YOLO\n\n    Параметры:\n    -sample: строка данных из датафрейма (logo_dataset)\n    -classname2idx: словарь меток (dict, default: classname2idx)\n    '''\n    train_folder = \"train\" if sample[\"is_train\"] else \"val\"\n    input_file = sample[\"file_path\"]\n    output_file = os.path.join(dataset_dst_dir, train_folder, \"__\".join(sample[\"file_path\"].split(os.sep)[-3:]))\n    \n    # print(train_folder)\n    # print(input_xml_file)\n    # print(output_xml_file)\n    \n    if not os.path.exists(output_file):\n        shutil.copy(input_file, output_file)\n    if not os.path.exists(output_file.replace(\".jpg\", \".txt\")):\n        convert_to_YOLO_format(input_file.replace(\".jpg\", \".xml\"), \n                            output_file.replace(\".jpg\", \".txt\"), classname2idx)\n    return True\n\nfirst_row = final_logo_dataset.iloc[1][:]\n# print(first_row)\ncopy_to_working_dir(first_row)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.663319Z","iopub.execute_input":"2025-02-01T21:53:40.663602Z","iopub.status.idle":"2025-02-01T21:53:40.691801Z","shell.execute_reply.started":"2025-02-01T21:53:40.663572Z","shell.execute_reply":"2025-02-01T21:53:40.691036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_yolo_data(logo_dataset:pd.DataFrame = final_logo_dataset):\n    '''\n    Функция создаст каталог для обучения модели YOLO\n\n    Параметры:\n    -logo_dataset: исходный датасет (pd.DataFrame, default: final_logo_dataset)\n    '''\n\n    copy_to_working_dir_results = []\n\n    with ThreadPoolExecutor() as e:\n        for _, row in tqdm(logo_dataset.iterrows()):\n            status = e.submit(copy_to_working_dir, dict(row))\n            copy_to_working_dir_results.append(status)\n\n    copy_to_working_results = logo_dataset_copy.apply(lambda x: copy_to_working_dir(x), axis=1)\n    print(copy_to_working_results.sum(), logo_dataset_copy.shape[0])\n\ncreate_yolo_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:53:40.692636Z","iopub.execute_input":"2025-02-01T21:53:40.692885Z","iopub.status.idle":"2025-02-01T21:59:29.658333Z","shell.execute_reply.started":"2025-02-01T21:53:40.692854Z","shell.execute_reply":"2025-02-01T21:59:29.657004Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Далее необходимо создать класс Dataset","metadata":{"execution":{"iopub.status.busy":"2025-02-01T18:55:04.710598Z","iopub.execute_input":"2025-02-01T18:55:04.710977Z","iopub.status.idle":"2025-02-01T18:55:04.717415Z","shell.execute_reply.started":"2025-02-01T18:55:04.710951Z","shell.execute_reply":"2025-02-01T18:55:04.716017Z"}}},{"cell_type":"code","source":"from PIL import Image\n\nclass LogoDataset(Dataset):\n\n        '''\n        Простой класс датасета для получения изображений и меток. \n\n        Функции:\n        def __init__(self, ...):\n        Параметры:\n        -root: путь к корню каталога (str, default: '/kaggle/working/logodet3k/train')\n        -transform: torch transform (default: None)\n\n        def __len__(self):\n        Возвращает длину датасета\n\n        def __getitem__(self, idx):\n        Возвращает изображение-метку по индексу в датасете\n\n        '''\n\n        def __init__(self, root:str = '/kaggle/working/logodet3k/train', transform = None):\n            self.root_dir = root\n            self.transform = transform\n            self.image_files = [f for f in os.listdir(root) if f.endswith('.jpg')]\n\n        def __len__(self):\n            return len(self.image_files)\n            \n        def __getitem__(self, idx):\n\n            img_name = self.image_files[idx]\n            img_path = os.path.join(self.root_dir, img_name)\n            txt_path = os.path.join(self.root_dir, img_name.replace('.jpg', '.txt'))\n            \n            image = Image.open(img_path).convert('RGB')\n\n            with open(txt_path, 'r') as file:\n                line = file.readline().strip()\n                class_index, x_center, y_center, width, height = map(float, line.split())\n\n            img_width, img_height = image.size\n            x_center = int(x_center * img_width)\n            y_center = int(y_center * img_height)\n            width = int(width * img_width)\n            height = int(height * img_height)\n\n            left = int(x_center - width / 2)\n            top = int(y_center - height / 2)\n            right = int(x_center + width / 2)\n            bottom = int(y_center + height / 2)\n\n            cropped_image = image.crop((left, top, right, bottom))\n\n            if self.transform:\n                cropped_image = self.transform(cropped_image)\n            \n            return cropped_image, int(class_index)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:29.660150Z","iopub.execute_input":"2025-02-01T21:59:29.660409Z","iopub.status.idle":"2025-02-01T21:59:29.669648Z","shell.execute_reply.started":"2025-02-01T21:59:29.660387Z","shell.execute_reply":"2025-02-01T21:59:29.668865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Получение датасетов","metadata":{}},{"cell_type":"code","source":"def get_datasets(train_path:str = '/kaggle/working/logodet3k/train',\n                val_path:str = '/kaggle/working/logodet3k/val', \n                idx_to_visualize = None,\n                transform = None,\n                label2name:dict = idx2classname,\n                dataset_type = LogoDataset):\n    '''\n    Функция для получения train и test датасетов\n    \n    Параметры:\n    -train_path: путь к тренировочному набору файлов (str, default: '/kaggle/working/logodet3k/train')\n    -val_path: путь к валидационному набору файлов (str, default: '/kaggle/working/logodet3k/val')\n    -idx_to_visualize: индекс датасета для визуализации (default: None)\n    -transform: torch transform (default: None)\n    -label2name: словарь метка <-> название (dict, default: idx2classname)\n    -dataset_type: тип датасета (default: LogoDataset)\n    '''\n\n    logo_train_dataset = dataset_type(train_path, transform)\n    logo_val_dataset = dataset_type(val_path, transform)\n\n    print(f\"Размер тренировочного датасета: {len(logo_train_dataset)}\")\n    print(f\"Размер валидационного датасета: {len(logo_val_dataset)}\")\n\n    if idx_to_visualize is not None:\n        \n        image, label = logo_train_dataset[idx_to_visualize]\n        name = label2name[label]\n        plot_image(image, name)\n\n    return logo_train_dataset, logo_val_dataset\n\ntrain_logo_dataset, val_logo_dataset = get_datasets(idx_to_visualize = 0,\n                                                    transform = base_transform)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:29.670381Z","iopub.execute_input":"2025-02-01T21:59:29.670592Z","iopub.status.idle":"2025-02-01T21:59:30.282408Z","shell.execute_reply.started":"2025-02-01T21:59:29.670564Z","shell.execute_reply":"2025-02-01T21:59:30.281630Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Работает!","metadata":{}},{"cell_type":"markdown","source":"Проверки размерностей","metadata":{}},{"cell_type":"code","source":"train_logo_dataset[0][0].size(), train_logo_dataset[1][0].size(), train_logo_dataset[2][0].size()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:30.283478Z","iopub.execute_input":"2025-02-01T21:59:30.283802Z","iopub.status.idle":"2025-02-01T21:59:30.299431Z","shell.execute_reply.started":"2025-02-01T21:59:30.283767Z","shell.execute_reply":"2025-02-01T21:59:30.298606Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Создание dataloader'ов","metadata":{}},{"cell_type":"code","source":"def get_dataloaders(train_dataset = train_logo_dataset,\n                   val_dataset = val_logo_dataset,\n                   batch_size:int = 64,\n                   shuffle_train:bool = True,\n                   shuffle_test:bool = False):\n    '''\n    Функция получения тренировочного и тестового даталоадеров\n\n    Параметры:\n    -train_dataset: тренировочный датасет (default: train_logo_dataset)\n    -val_dataset: валидационный датасет (default: val_logo_dataset)\n    -batch_size: размер батча (int, default: 64)\n    -shuffle_train: флаг для перемешивания train (bool, default: True)\n    -shuffle_test: флаг для перемешивания test (bool, default: False)\n\n    Возвращает:\n    -Кортеж итераторов (train_loader, val_loader)\n    '''\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle_train)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle_test)\n\n    return train_loader, val_loader\n\ntrain_loader, val_loader = get_dataloaders(batch_size = 312)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:30.300424Z","iopub.execute_input":"2025-02-01T21:59:30.300685Z","iopub.status.idle":"2025-02-01T21:59:30.305626Z","shell.execute_reply.started":"2025-02-01T21:59:30.300665Z","shell.execute_reply":"2025-02-01T21:59:30.304896Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Проверка Даталоадеров","metadata":{}},{"cell_type":"code","source":"# for images, labels in tqdm(train_loader):\n    # print(len(images))\n    # print(labels)\n    # break\n    # pass\n# print(\"Успешно!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:30.306428Z","iopub.execute_input":"2025-02-01T21:59:30.306646Z","iopub.status.idle":"2025-02-01T21:59:30.322671Z","shell.execute_reply.started":"2025-02-01T21:59:30.306626Z","shell.execute_reply":"2025-02-01T21:59:30.321980Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Теперь нужно создать класс ```pl.LightningModule```","metadata":{}},{"cell_type":"code","source":"class modelArcFaceLoss(pl.LightningModule):\n\n\t'''\n\tКласс модели с функцией потерь ArcFaceLoss (наследует методы из pl.LightningModule)\n\t'''\n\n\tdef __init__(\n\t\t\tself,\n\t\t\tmodel=resnet18(pretrained=True), # базовая модель resnet18\n\t\t\tembedding_size=128,\n\t\t\tdistance_metric=distances.CosineSimilarity(),\n\t\t\treducer=reducers.ThresholdReducer(low=0),\n\t\t\tloss_fn=losses.ArcFaceLoss,  # Вот она ArcFace из pytorch_metric_learning\n\t\t\tarcface_margin=0.5,  # margin гиперпараметр\n\t\t\tarcface_scale=64,  #scale гиперпараметр\n\t\t\toptimizer=Adam, \n\t\t\toptimizer_params={'lr': 0.001, 'weight_decay': 0.0001},\n\t\t\tclass_dict=idx2classname,\n\t\t\tmin_lr=1e-5,\n\t\t\tstep_size=8,\n\t\t\tgamma=0.5\n\t\t\t):\n\t\t\n\t\t'''\n\t\tКонуструктор объекта класс def __init__(self, ...)\n\n\t\tПарамеры:\n\t\t-model: Базовая модель (default: resnet18(pretrained = True))\n\t\t-embedding_size: Размер эмбеддингов после сверточных слоев для решения задачи Metric Learning (default = 128)\n\t\t-distance_metric: Метрика подсчета расстояния между объектами (default: CosineSimilarity())\n\t\t-reduce: Функция редукции потерь, которая используется для фильтрации значений loss на основе порогового значения.\n\t\tНапример, ThresholdReducer(low=0) игнорирует все значения потерь ниже 0.\n\t\tЭто может повысить устойчивость к шуму в данных (default: ThresholdReducer(low=0))\n\t\t-loss_fn: функция потерь (default: ArcFaceLoss)\n\t\t-arcface_margin: Смещение угла в формуле функции потерь (default: 0.5)\n\t\t-arcface_scale: Масшатабирующий параметр в формуле функции потерь (default: 64)\n\t\t-optimizer: оптимизатор (default: Adam)\n\t\t-optimizer_params: параметры оптимизатора\n\t\t-class_dict: словарь Dict label->idx2classname\n\t\t-min_lr: минимальный шаг сходимости (тот предел, до которого уменьшается lr в процессе обучения)\n\t\t-step_size: число эпох, через которое экпоненциально уменьшаем шаг сходимости\n\t\t-gamma: уменьшающий множитель \n\n\t\tИнициализирует всё необходимое\n\n\t\t'''\n\n\t\tsuper(modelArcFaceLoss, self).__init__()\n\n\t\t# Модель и её параметры (Архитектура + Функция потерь + Оптимизатор)\n\t\tself.backbone = model,\n\t\tself.backbone = self.backbone[0]\n\t\tself.embedding_size = embedding_size\n\t\tself.backbone.fc = nn.Linear(self.backbone.fc.in_features, self.embedding_size)\n\t\tself.fc = nn.Linear(self.embedding_size, self.embedding_size)\n\t\tself.distance = distance_metric\n\t\tself.reducer = reducer\n\t\tself.arcface_margin = arcface_margin\n\t\tself.arcface_scale = arcface_scale\n\t\tself.loss_fn = loss_fn(\n\t\t\tnum_classes=len(class_dict),\n\t\t\tembedding_size=self.embedding_size,\n\t\t\tmargin=self.arcface_margin,\n\t\t\tscale=self.arcface_scale\n\t\t)\n\n\t\tself.optimizer_params = optimizer_params\n\t\tself.optimizer = optimizer(self.parameters(), **self.optimizer_params)\n\t\tself.class_dict = class_dict\n\n\t\t# Если мы хотим еще параллельно решать задачу классификации на основе привычной CrossEntropy\n\t\tself.classifier_head = nn.Sequential(\n\t\t\tnn.ReLU(),\n\t\t\tnn.Linear(in_features=self.embedding_size, out_features=len(self.class_dict))\n\t\t)\n\t\tself.classif_loss = torch.nn.CrossEntropyLoss()\n\t\tself.save_hyperparameters()\n\t\tself.gamma = gamma\n\t\tself.step_size = step_size\n\t\tself.scheduler = StepLR(self.optimizer, step_size=self.step_size, gamma=self.gamma)\n\t\tself.min_lr = min_lr\n\n\t\t# Эмбеддинги для подсчета метрик в конце валидации\n\t\tself.val_embeddings = []\n\t\tself.val_labels = []\n\n\tdef forward(self, input_x):\n\t\t'''\n\t\tforward модели после подачи batch_size:\n\n\t\tПараметры:\n\t\t-self\n\t\t-input_x: входой пакет картинок\n\n\t\tВозвращает эмбеддинг картинки\n\t\t'''\n\n\t\t# Прогон через CNN\n\t\tcnn_output = self.backbone(input_x)\n\t\t# Прогон через линейные слои\n\t\tembedding = self.fc(cnn_output)\n\t\treturn embedding\n\n\tdef training_step(self, batch, batch_idx):\n\t\t\t'''\n\t\t\tЧасть train логики: подаем батч, разбиваем на (images, labels)\n\t\t\tВозвращем loss, по которому будет считаться градиент\n\t\t\t'''\n\n\t\t\timages, labels = batch\n\t\t\tembeddings = self(images)\n\n\t\t\t# ArcFace loss\n\t\t\tloss_arcface = self.loss_fn(embeddings, labels)\n\t\t\tfinal_loss = loss_arcface\n\n\t\t\tself.log('train_loss', final_loss, sync_dist=True)\n\t\t\treturn final_loss\n\n\tdef on_train_start(self):\n\t\tself.train()\n\n\tdef validation_step(self, batch, batch_idx):\n\t\t\t\n\t\t\t'''\n\t\t\tЛогика на валидации: подаем батч, считаем loss на валидации и записываем в tensor_board\n\t\t\tИ добавляем эмбеддинги и метки для подсчёта метрик\n\t\t\t'''\n\n\t\t\timages, labels = batch\n\t\t\tembeddings = self(images)\n\n\t\t\tloss_arcface = self.loss_fn(embeddings, labels)\n\n\t\t\tfinal_loss = loss_arcface\n\t\t\tself.log('validation_loss', final_loss, sync_dist=True)\n\n\t\t\tself.val_embeddings.append(embeddings)\n\t\t\tself.val_labels.append(labels)\n\n\tdef on_validation_epoch_end(self):\n\t\t\t\n\t\t\t'''\n\t\t\tЛогика в конце валидации: считает ключевую метрики на валидации, а именно precision@1:\n            \n\t\t\t-precision@1\n\t\t\t-Обнуляет массивы эмбеддингов и меток в конце\n\t\t\t'''\n\n\t\t\tall_embeddings = torch.cat(self.val_embeddings)\n\t\t\tall_labels = torch.cat(self.val_labels)\n\n\t\t\taccuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1, knn_func=CustomKNN(\n\t\t\t\tdistances.CosineSimilarity(), batch_size=64))\n\n\t\t\tmetrics = accuracy_calculator.get_accuracy(all_embeddings, all_labels)\n\t\t\tprecision_at_1 = metrics[\"precision_at_1\"]\n\t\t\tself.log('precision_at_1_epoch', precision_at_1, sync_dist=True)\n\n\t\t\tself.val_embeddings = []\n\t\t\tself.val_labels = []\n\n\tdef on_validation_start(self):\n\t\t\tself.eval()\n\n\tdef configure_optimizers(self):\n\t\t'''\n\t\tОбъявление оптимизатора и его фичей\n\t\t'''\n\t\t\n\t\treturn {\n\t\t\t'optimizer': self.optimizer,\n\t\t\t'lr_scheduler': {\n\t\t\t\t'scheduler': self.scheduler,\n\t\t\t\t'interval': 'epoch',\n\t\t\t\t'frequency': 1,\n\t\t\t\t'reduce_on_plateau': False,\n\t\t\t\t'monitor': 'validation_loss',\n\t\t\t}\n\t\t}\n\n\tdef lr_scheduler_step(self, scheduler, metric):\n\t\t'''\n\t\tОбновление шага сходимости\n\t\t'''\n\n\t\tscheduler.step()\n\t\tself._adjust_learning_rate()\n\n\tdef _adjust_learning_rate(self):\n\t\t'''\n\t\tПроверка достижения предела learning_rate (self.min_lr)\n\t\t'''\n\t\t\n\t\tfor param_group in self.optimizer.param_groups:\n\t\t\tparam_group['lr'] = max(param_group['lr'], self.min_lr)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:30.323447Z","iopub.execute_input":"2025-02-01T21:59:30.323739Z","iopub.status.idle":"2025-02-01T21:59:31.204826Z","shell.execute_reply.started":"2025-02-01T21:59:30.323712Z","shell.execute_reply":"2025-02-01T21:59:31.204136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Инициализация модели и её гиперпараметров","metadata":{}},{"cell_type":"code","source":"'''\nБлок инициализации модели и её фичей\n'''\n\n'''Объявляем device (на kaggle 'gpu')'''\ndevice = 'gpu' if torch.cuda.is_available() else 'cpu'\nprint(device)\n\n'''Инициализируем модель. Через 15 (step_size = 15) эпох уменьшаем learning_rate'''\nmodel = modelArcFaceLoss(step_size=15)\npl_model = model\n\n'''\nПолезные утилиты:\n\n-early_stopping: обрываем обучение, если loss на валидации не падает в течение 5 эпох\n-lr_monitor: мониторинг шага сходимости (чтобы его тоже логировать в TensorBoard)\n'''\nearly_stopping = EarlyStopping(monitor=\"validation_loss\", mode=\"min\", patience=5)\nlr_monitor = LearningRateMonitor(logging_interval='step')\n\n\n'''\nЛогирование по качеству в TensorBoard:\n\n-checkpoint_callback_1: сохранять Топ-3 по лоссу на валидации\n-checkpoint_callback_2: сохранять Топ-2 по метрике precision_at_1\n'''\ntensorboard_logger = TensorBoardLogger(\"tb_logs\", name=\"cars196_model_arcface_lr_scheduler_70\")\ncheckpoint_callback_1 = ModelCheckpoint(\n    monitor='validation_loss',  \n    mode='min', \n    save_top_k=3, \n    filename='best-checkpoint-arcfaceloss-{epoch:02d}-{validation_loss:.2f}'  \n)\n\ncheckpoint_callback_2 = ModelCheckpoint(\n    monitor='precision_at_1_epoch',  \n    mode='max', \n    save_top_k=2,  \n    filename='best-precision-arcfaceloss-{epoch:02d}-{precision_at_1_epoch:.2f}'  \n)\n\n'''\nPyTorchLightning Module:\n\nКлючевые параметры:\n-max_epochs = 30: Максимум 30 эпох будем обучать\n-min_epochs = 15: Минимум 15 эпох будем обучать\n'''\n\ntrainer = pl.Trainer(\n    max_epochs=30,\n    min_epochs = 15,\n    accelerator=device,\n    devices=1,\n    logger=tensorboard_logger,\n    callbacks=[checkpoint_callback_1, checkpoint_callback_2, early_stopping, lr_monitor],\n    log_every_n_steps=1,  \n    enable_progress_bar=True  \n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T21:59:31.205584Z","iopub.execute_input":"2025-02-01T21:59:31.205814Z","iopub.status.idle":"2025-02-01T21:59:31.305373Z","shell.execute_reply.started":"2025-02-01T21:59:31.205789Z","shell.execute_reply":"2025-02-01T21:59:31.304707Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Обучение","metadata":{}},{"cell_type":"code","source":"'''Блок обучения'''\ntrainer.fit(pl_model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T22:01:47.249876Z","iopub.execute_input":"2025-02-01T22:01:47.250309Z","iopub.status.idle":"2025-02-01T22:10:03.369249Z","shell.execute_reply.started":"2025-02-01T22:01:47.250280Z","shell.execute_reply":"2025-02-01T22:10:03.367938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}